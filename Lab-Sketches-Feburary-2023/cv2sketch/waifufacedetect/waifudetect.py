"""
ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ 

        â–ˆâ–€â–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–€â–€â€ƒâ–ˆâ–„â–‘â–ˆâ€ƒ â€ƒâ–ˆâ–€â€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–‘â–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–€â–€â€ƒâ–ˆâ–€â–€â€ƒ â€ƒâ–ˆâ–€â–€â€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–€â–„â–€â–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–‘â–ˆâ€ƒâ–€â–ˆâ–€â€ƒâ–ˆâ–€â–€â€ƒâ–ˆâ–€â–ˆâ€ƒ â€ƒâ–ˆâ–‘â–ˆâ€ƒâ–ˆâ€ƒâ–ˆâ–€â€ƒâ–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆâ€ƒ â€ƒâ–„â–€â€ƒâ–ˆâ–€â–€â€ƒâ–ˆâ–‘â–ˆâ€ƒâ–€â–ˆâ€ƒâ–€â–„
        â–ˆâ–„â–ˆâ€ƒâ–ˆâ–€â–€â€ƒâ–ˆâ–ˆâ–„â€ƒâ–ˆâ–‘â–€â–ˆâ€ƒ â€ƒâ–„â–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–ˆâ–€â–„â€ƒâ–ˆâ–„â–„â€ƒâ–ˆâ–ˆâ–„â€ƒ â€ƒâ–ˆâ–„â–„â€ƒâ–ˆâ–„â–ˆâ€ƒâ–ˆâ–‘â–€â–‘â–ˆâ€ƒâ–ˆâ–€â–€â€ƒâ–ˆâ–„â–ˆâ€ƒâ–‘â–ˆâ–‘â€ƒâ–ˆâ–ˆâ–„â€ƒâ–ˆâ–€â–„â€ƒ â€ƒâ–€â–„â–€â€ƒâ–ˆâ€ƒâ–„â–ˆâ€ƒâ–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆâ€ƒ â€ƒâ–€â–„â€ƒâ–ˆâ–„â–„â€ƒâ–€â–„â–€â€ƒâ–ˆâ–„â€ƒâ–„â–€â€ƒ


                                    â–ˆâ–€â–€â€ƒâ–„â–€â–ˆâ€ƒâ–ˆâ–€â–€â€ƒâ–ˆâ–€â–€â€ƒ â€ƒâ–ˆâ–€â–„â€ƒâ–ˆâ–€â–€â€ƒâ–€â–ˆâ–€â€ƒâ–ˆâ–€â–€â€ƒâ–ˆâ–€â–€â€ƒâ–€â–ˆâ–€â€ƒâ–ˆâ€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆ
                                    â–ˆâ–€â–‘â€ƒâ–ˆâ–€â–ˆâ€ƒâ–ˆâ–„â–„â€ƒâ–ˆâ–ˆâ–„â€ƒ â€ƒâ–ˆâ–„â–€â€ƒâ–ˆâ–ˆâ–„â€ƒâ–‘â–ˆâ–‘â€ƒâ–ˆâ–ˆâ–„â€ƒâ–ˆâ–„â–„â€ƒâ–‘â–ˆâ–‘â€ƒâ–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆ
                                        
                                        cÍ¨oÍ¦dÍ©eÍ¤dÍ© Ð²â·¡y geÍ¤neÍ¤sÍ›iÍ¥sÍ›giÍ¥rÍ¬
                                        â£¿â£¿â£¿â£¿â£¿â£¿â Ÿâ ‹â â£€â£¤â¡„â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â ˆâ¢¿â£¿â£¿
                                        â£¿â£¿â£¿â£¿â ‹â â €â €â ºâ ¿â¢¿â£¿â£„â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â ˜â »â£¿
                                        â£¿â£¿â¡Ÿâ â €â €â €â €â €â €â €â €â €â €â €â €â¢€â£€â£¤â£¤â£¤â£¤â €â €â €â €â €â£¤â£¦â£„â €â €
                                        â£¿â¡Ÿâ €â €â €â €â €â €â €â €â €â €â¢€â£¤â£¶â£¿â â£¿â£¿â£¿â£¿â£¿â£â €â €â €â ›â ™â ›â ‹â €â €
                                        â¡¿â €â €â €â €â €â €â €â €â¡€â €â£°â£¿â£¿â£¿â£¿â¡„â ˜â£¿â£¿â£¿â£¿â£·â „â €â €â €â €â €â €â €â €
                                        â¡‡â €â €â €â €â €â €â €â ¸â ‡â£¼â£¿â£¿â£¿â£¿â£¿â£·â£„â ˜â¢¿â£¿â£¿â£¿â£…â €â €â €â €â €â €â €â €
                                        â â €â €â €â£´â£¿â €â£â££â£¸â£¿â£¿â£¿â£¿â£¿â Ÿâ ›â ›â €â Œâ »â£¿â£¿â£¿â¡„â €â €â €â €â €â €â €
                                        â €â €â €â£¶â£®â£½â£°â£¿â¡¿â¢¿â£¿â£¿â£¿â£¿â£¿â¡€â¢¿â£¤â „â¢ â£„â¢¹â£¿â£¿â£¿â¡†â €â €â €â €â €â €
                                        â €â €â €â£¿â£¿â£¿â£¿â£¿â¡˜â£¿â£¿â£¿â£¿â£¿â£¿â ¿â£¶â£¶â£¾â£¿â£¿â¡†â¢»â£¿â£¿â ƒâ¢ â –â ›â£›â£·â €
                                        â €â €â¢¸â£¿â£¿â£¿â£¿â£¿â£¿â£¾â£¿â£¿â£¿â£¿â£¿â£¿â£®â£â¡»â ¿â ¿â¢ƒâ£„â£­â¡Ÿâ¢€â¡Žâ£°â¡¶â£ªâ£¿â €
                                        â €â €â ˜â£¿â£¿â£¿â Ÿâ£›â »â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£·â£¿â£¿â£¿â¡¿â¢â£¾â£¿â¢¿â£¿â£¿â â €
                                        â €â €â €â£»â£¿â¡Ÿâ ˜â ¿â ¿â Žâ »â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£µâ£¿â£¿â §â£·â Ÿâ â €â €
                                        â¡‡â €â €â¢¹â£¿â¡§â €â¡€â €â£€â €â ¹â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â£¿â ‹â¢°â£¿â €â €â €â €
                                        â¡‡â €â €â €â¢»â¢°â£¿â£¶â£¿â¡¿â ¿â¢‚â£¿â£¿â£¿â£¿â£¿â£¿â£¿â¢¿â£»â£¿â£¿â£¿â¡â €â €â â €â €â €â €
                                        â£·â €â €â €â €â ˆâ ¿â Ÿâ£â£´â£¾â£¿â£¿â ¿â ¿â£›â£‹â£¥â£¶â£¿â£¿â£¿â£¿â£¿â €â €â €â €â €â €â €â € â£¿â¡€


CV2 stands for computer vision and is a third party python module that allows the ability to manipulate image and video data and face recognition
AI capabilities, in this module we will use Face AI recognition, Object detection to detect faces images and videos using opencv (CV2) to scan 
and diagnose these traits I have just explained.   

ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚ ðŸ…¶ðŸ…´ðŸ…½ðŸ…´ðŸ†‚ðŸ…¸ðŸ†‚
"""
# import modules
import cv2
from typing import Type

# cascade file
anime_cascade_file = r'Scrap-Yard\Lab-Sketches-Feburary-2023\cv2sketch\waifufacedetect\detection_model\lbpcascade_animeface.xml'

# waifu method
def waifufacedetect(filename = anime_cascade_file, image_color: int = 0, image_name: str = 'image.txt') -> Type[None]:
    ''' # waifufacedetect() method
    detects the faces of waifus and many more features like analyzing contours using opencv
    '''

    import cv2
    global gray

    # methods
    def findcontours(img: str):
        
        # refer to global (scope)
        global img_contours
        
        # threshold image 
        ret , image_binary = cv2.threshold(src=img,thresh= 127, maxval= 255, type= cv2.THRESH_BINARY)
        
        # Find the contours in the binary image
        contours, hierarchy = cv2.findContours(image_binary, cv2.CV_8UC1, cv2.CHAIN_APPROX_SIMPLE)
        
        # Draw the contours on the original image
        img_contours = cv2.drawContours( # <- draws contours
                                        # contour settings
                                        image = img, contours = contours, 
                                        contourIdx = -1,
                                        color = (0, 0, 255), # red
                                        thickness = 2,
                                        )
    
    imagepath = r'Scrap-Yard\Lab-Sketches-Feburary-2023\cv2sketch\waifufacedetect\image_dataset\cow_waifu_suggestive.png'
    
    # setting the detection model classifier
    model = cv2.CascadeClassifier(filename)
    
    # load image
    img = cv2.imread(filename = imagepath, flags = cv2.IMREAD_COLOR)
    color_image = img.copy() # preserve the colored image
    
    # greyscale image and brighten contrast
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #  Converts an image to a greyscale image.
    gray = cv2.equalizeHist(gray) # The algorithm normalizes the brightness and increases the contrast of the image.
    
    # image array
    image_types = [gray, color_image]
    
    # locates contours in image
    #findcontours(img = image_types[image_color])
    
    # detect faces
    faces = model.detectMultiScale(image_types[image_color], 
                                    # detector settings
                                    scaleFactor = 1.1,
                                    minNeighbors = 5,
                                    minSize = (25, 25))

    # draw rectangles on image
    for x, y, w, h in faces:
        cv2.rectangle(img = image_types[image_color], pt1 = (x, y), pt2 = (x + w, y + h ), color=(0, 0, 255), thickness= 2)

    # save image
    #cv2.imwrite(filename=image_name, img=image_types[image_color]) # imwrite saves the image to the specified file.
    
    
    # display images with detected waifu faces
    cv2.namedWindow(winname='WaifuThotFaceDectect', flags=cv2.WINDOW_AUTOSIZE)
    cv2.imshow(winname='WaifuThotFaceDectect', mat = image_types[image_color])
    cv2.waitKey(0) # user presses key to close window
    cv2.destroyAllWindows()

def face_video_detect():
    ''' # waifu_face_gif_detect()
    detects the faces within gif file formats
    '''

    import cv2
    
    # face detection machine learning model to use/ # Initialize the face detection classifier
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
    # path to video
    video_path = r'Scrap-Yard\Lab-Sketches-Feburary-2023\cv2sketch\waifufacedetect\video_sources\mike wheeler being annoyed for 5 minutes straight.mp4'
    
    # create capture object
    cap = cv2.VideoCapture(video_path) # capture obj
    fps = cap.get(cv2.CAP_PROP_FPS) # Get the frame rate of the video
    print(fps)
    delay_time = 33 # Calculate the delay time for each frame to achieve 30 fps
    
    # read frames and detect faces
    while cap.isOpened():
        ret, frame = cap.read() # read each singular frame
        
        # If there are no more frames, exit the loop
        if not ret:
            break 
    
        # Convert the frame to grayscale
        grey = cv2.cvtColor(src=frame, code=cv2.COLOR_BGR2GRAY)


        # Detect faces in the grayscale frame
        faces = face_cascade.detectMultiScale(
                                            # detector options
                                            grey, 
                                            scaleFactor = 1.3, 
                                            minNeighbors = 5)

        # Draw rectangles around the detected faces
        for x, y, w, h in faces:
            cv2.rectangle(img= frame, pt1= (x, y), pt2= (x + w, y + h), color= (0, 255, 0), thickness= 2)

        # Display the processed frame
        cv2.imshow('frame', frame)
        
        # Exit the loop if the user presses 'q'
        if cv2.waitKey(delay_time) == ord('q'):
            break
    
    # Release the video and close the window
    cap.release()
    cv2.destroyAllWindows()

# calls
#waifufacedetect(image_color=0) # display waifu greyscaled
#waifufacedetect(image_color=1) # display waifu colored
face_video_detect()